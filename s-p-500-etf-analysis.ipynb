{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Financial Market Data Analysis\n\nIn this project i will conduct a time series analysis of historical financial market data on the S&P 500 ETF. The analysis is meant to be exploratory in nature, and is not meant to provide advice/recommendations.","metadata":{}},{"cell_type":"markdown","source":"## Getting Data\n\nI will be using pandas: datareader to read in data from Yahoo Finance. The data will span 3 years, from 1st Jan 2017 to 1st Jan 2020.\n\n### Import relevant packages","metadata":{}},{"cell_type":"code","source":"pip install --upgrade mplfinance","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas_datareader import data, wb\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mplfinance.original_flavor import candlestick_ohlc\nimport matplotlib.dates as mdates\nfrom scipy.stats import norm\n%matplotlib inline\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start=datetime.datetime(2017,1,1)\nend=datetime.datetime(2020,1,1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPY=data.DataReader('SPY','yahoo',start,end)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Examine the data","metadata":{}},{"cell_type":"code","source":"SPY.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPY.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPY.describe()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.sum(pd.isnull(SPY))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are working with 754 observations over the time period, with no missing values. All our columns are of the float type.\n\n## Visualize the data\n","metadata":{}},{"cell_type":"code","source":"#Set font size\nsns.set(font_scale=1.2)\n\n# Set graph style\nsns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"1.0\",  'axes.grid': True, \"grid.color\": \"0.85\",\n              \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.2', \"xtick.color\": \"0.3\",\n              'ytick.color': '0.3'})\n\n\nplt.figure(figsize=(12,8))\nplt.plot(SPY[['High', 'Low', 'Open','Adj Close']])\nplt.title('Plot of Daily High, Low, Open and Adjusted Close prices')\nplt.xlabel('Date',fontsize=20)\nplt.ylabel('Price ($)',fontsize=20)\nplt.legend(['High','Low','Open','Adj Close'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set font size\nsns.set(font_scale=1.2)\n\n# Set graph style\nsns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\",  'axes.grid': True, \"grid.color\": \"0.85\",\n               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n               'ytick.color': '0.4'})\n\n\nplt.figure(figsize=(12,8))\nplt.plot(SPY[['Volume']])\nplt.title('Plot of Daily Volume Traded')\nplt.xlabel('Date',fontsize=20)\nplt.ylabel('Volume',fontsize=20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inspecting the plot on Daily Prices is difficult, given the overlaps between High, Low and Open prices. To better visualize the price changes, I will create a candlestick chart. Individual candlesticks display the size of price movements, with green corresponding to an upward movement and red representing a downward movement.\n\nIn order to use the candlestick_ohlc() function, I will need to format the dataframe accordingly. I will also limit the date range to 2 weeks initially, to better visualize the price changes.","metadata":{}},{"cell_type":"code","source":"spy_candle=SPY.drop(['Volume','Adj Close'],axis=1)\ndates = spy_candle.index.tolist()\ndates = pd.DataFrame(mdates.date2num(dates), columns = [\"Date\"], index = spy_candle.index)\nspy_candle=pd.concat([dates,spy_candle],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Shorten time interval\nnew_start=datetime.date(2018,10,10)\nnew_end=datetime.date(2018,12,10)\nohlc = spy_candle[['Date','Open','High','Low','Close']]\n\n#Create figure\nfig ,ax = plt.subplots(figsize=(12,8))\n\n#Plot candlestick\ncandlestick_ohlc(ax,ohlc.values,\n                 width=0.6,\n                colorup='green',\n                colordown='red')\nplt.xlabel(\"Date\")\nplt.ylabel(\"Price($)\")\n\nax.set_xlim([new_start,new_end])\nax.set_ylim([255,290])\nax.set_axisbelow(True)\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n\nplt.tight_layout()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Examine Returns\n\nUse pct_change on 'Close' column to calculate returns","metadata":{}},{"cell_type":"code","source":"SPY['Daily_Returns']=SPY['Close'].pct_change()\nSPY.head()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Identify the dates where S&P 500 ETF had the worst and best returns over the period 1st Jan 2017 to 1st Jan 2020.","metadata":{}},{"cell_type":"code","source":"SPY['Daily_Returns'].idxmin()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPY['Daily_Returns'].idxmax()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2018 was the year that S&P 500 ETFs had the best and worst returns during our observed time period.\n\n## Visualize returns\n\nCreate a distribution plot for returns of S&P 500 ETF","metadata":{}},{"cell_type":"code","source":"sns.displot(data=SPY['Daily_Returns'],color='blue',bins=100,height=8,aspect=12/8,kde=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Moving Averages\n\nAnalyze moving averages of S&P 500 ETF in the year 2018. \nPlot the rolling 30 day average against close price.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nSPY['Close'].loc['2018-01-01':'2019-01-01'].rolling(window=30).mean().plot(label='30-Day Average')\nSPY['Close'].loc['2018-01-01':'2019-01-01'].plot(label='S&P Close')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Value at Risk\n<br>\nVaR is an attempt to summarize the total risk in a portfolio with a single number. <br> This helps financial institutions assess whether they have sufficient capital reserves set aside to cover losses.\nIt is defined as the worst loss expected from holding a portfolio over a given period of time, given a confidence level 1 - \n$\\alpha$ <br>\nA more simplified way of looking at it: Given $\\alpha$ of 1 %, and a duration of 1 month, what is the maximum loss over that month? <br>\n<br>\n### Examine 2 definitions of VaR<br>\n1. VaR = expected profit/loss minus worst case loss at the 1-$\\alpha$ confidence level\n2. Absolute VaR = - worst case loss at the 1-$\\alpha$ confidence level\n\n### 2 ways of calculating VaR<br>\n1. Parametric approach\n2. Historical, or non-parametric approach\n\n\n#### Notes\n1. Use Adj Close for calculating returns instead, as it gives a better idea of the overall value of the stock.\n2. Assume that a company bought 50,000 shares of S&P ETFs on 1st Jan 2020, at $312 per share.\n3. Find the one-day 99% VaR\n\n\n#### 1. Parametric approach\nRank the daily return rates from the smallest to largest, and use $\\alpha$ % to estimate the VaR of an investment.","metadata":{}},{"cell_type":"code","source":"SPY_var=SPY.drop('Daily_Returns',axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPY_var['Daily_Returns']=SPY_var['Adj Close'].pct_change(periods=-1)\nSPY_var=SPY_var[:-1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Num_shares=50000\nPrice_shares=312\n\npara_VaR=Num_shares*Price_shares*SPY_var['Daily_Returns'].std()*norm.ppf(0.99,0,1)\nprint('The one-day 99% VaR using parametric approach is {}'.format(round(para_VaR,2)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Historical Approach","metadata":{}},{"cell_type":"code","source":"AbsVaR=np.quantile((SPY_var['Daily_Returns'].tolist()),0.01)*-1*Num_shares*Price_shares","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meanVaR=np.mean(SPY_var['Daily_Returns'].tolist())*Num_shares*Price_shares","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_VaR=meanVaR+AbsVaR\nprint('The one-day 99% VaR using historical approach is {}'.format(round(hist_VaR,2)))","metadata":{},"execution_count":null,"outputs":[]}]}